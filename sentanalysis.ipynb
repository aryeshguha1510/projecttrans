{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":16295,"databundleVersionId":1099992,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport re\nimport shutil\nimport string\n\n\nfrom collections import Counter\n\n\nimport pandas as pd\nimport numpy as np\n\nimport sklearn\n\n\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"b6ad52f8-945d-408b-8cac-33809b69cc68","_cell_guid":"e042a9a4-09e5-4aeb-ad69-db54e981d650","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-07T17:10:39.989423Z","iopub.execute_input":"2024-03-07T17:10:39.989796Z","iopub.status.idle":"2024-03-07T17:10:39.995161Z","shell.execute_reply.started":"2024-03-07T17:10:39.989769Z","shell.execute_reply":"2024-03-07T17:10:39.994049Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef remove_url(text): \n    url_pattern  = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    return url_pattern.sub(r'', text)\n # converting return value from list to string\n\n\n\ndef clean_text(text ): \n    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n    delete_dict[' '] = ' ' \n    table = str.maketrans(delete_dict)\n    text1 = text.translate(table)\n    #print('cleaned:'+text1)\n    textArr= text1.split()\n    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n    \n    return text2.lower()","metadata":{"_uuid":"787d8159-755e-4a77-99a5-a05e8608556d","_cell_guid":"1407cf71-a3da-4f2c-b26b-05c2488be18c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-07T17:10:40.001298Z","iopub.execute_input":"2024-03-07T17:10:40.002200Z","iopub.status.idle":"2024-03-07T17:10:40.010835Z","shell.execute_reply.started":"2024-03-07T17:10:40.002163Z","shell.execute_reply":"2024-03-07T17:10:40.009025Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def get_sentiment(sentiment):\n    if sentiment == 'positive':\n        return 2\n    elif sentiment == 'negative':\n        return 1\n    else:\n        return 0","metadata":{"_uuid":"8caf9cf8-4dc8-454c-8811-94864b5f7829","_cell_guid":"c2055248-813b-4927-97e8-dde22e2773e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-07T17:10:40.012066Z","iopub.execute_input":"2024-03-07T17:10:40.012416Z","iopub.status.idle":"2024-03-07T17:10:40.020310Z","shell.execute_reply.started":"2024-03-07T17:10:40.012389Z","shell.execute_reply":"2024-03-07T17:10:40.019522Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"train_data= pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntrain_data.dropna(axis = 0, how ='any',inplace=True) \ntrain_data['Num_words_text'] = train_data['text'].apply(lambda x:len(str(x).split())) \nmask = train_data['Num_words_text'] >2\ntrain_data = train_data[mask]\nprint('-------Train data--------')\nprint(train_data['sentiment'].value_counts())\nprint(len(train_data))\nprint('-------------------------')\nmax_train_sentence_length  = train_data['Num_words_text'].max()\n\n\ntrain_data['text'] = train_data['text'].apply(remove_emoji)\ntrain_data['text'] = train_data['text'].apply(remove_url)\ntrain_data['text'] = train_data['text'].apply(clean_text)\n\ntrain_data['label'] = train_data['sentiment'].apply(get_sentiment)\n\ntest_data= pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\ntest_data.dropna(axis = 0, how ='any',inplace=True) \ntest_data['Num_words_text'] = test_data['text'].apply(lambda x:len(str(x).split())) \n\nmax_test_sentence_length  = test_data['Num_words_text'].max()\n\nmask = test_data['Num_words_text'] >2\ntest_data = test_data[mask]\n\nprint('-------Test data--------')\nprint(test_data['sentiment'].value_counts())\nprint(len(test_data))\nprint('-------------------------')\n\ntest_data['text'] = test_data['text'].apply(remove_emoji)\ntest_data['text'] = test_data['text'].apply(remove_url)\ntest_data['text'] = test_data['text'].apply(clean_text)\n\ntest_data['label'] = test_data['sentiment'].apply(get_sentiment)\n\nprint('Train Max Sentence Length :'+str(max_train_sentence_length))\nprint('Test Max Sentence Length :'+str(max_test_sentence_length))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:40.021741Z","iopub.execute_input":"2024-03-07T17:10:40.022213Z","iopub.status.idle":"2024-03-07T17:10:40.820453Z","shell.execute_reply.started":"2024-03-07T17:10:40.022187Z","shell.execute_reply":"2024-03-07T17:10:40.819377Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"-------Train data--------\nsentiment\nneutral     10704\npositive     8375\nnegative     7673\nName: count, dtype: int64\n26752\n-------------------------\n-------Test data--------\nsentiment\nneutral     1376\npositive    1075\nnegative     983\nName: count, dtype: int64\n3434\n-------------------------\nTrain Max Sentence Length :33\nTest Max Sentence Length :32\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid= train_test_split(train_data['text'].tolist(),\\\n                                                      train_data['label'].tolist(),\\\n                                                      test_size=0.2,\\\n                                                      stratify = train_data['label'].tolist(),\\\n                                                      random_state=0)\n\n\nprint('Train data len:'+str(len(X_train)))\nprint('Class distribution'+str(Counter(Y_train)))\n\n\nprint('Valid data len:'+str(len(X_valid)))\nprint('Class distribution'+ str(Counter(Y_valid)))\n\nprint('Test data len:'+str(len(test_data['text'].tolist())))\nprint('Class distribution'+ str(Counter(test_data['label'].tolist())))\n\n\ntrain_dat =list(zip(Y_train,X_train))\nvalid_dat =list(zip(Y_valid,X_valid))\ntest_dat=list(zip(test_data['label'].tolist(),test_data['text'].tolist()))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:40.822424Z","iopub.execute_input":"2024-03-07T17:10:40.822783Z","iopub.status.idle":"2024-03-07T17:10:40.865768Z","shell.execute_reply.started":"2024-03-07T17:10:40.822755Z","shell.execute_reply":"2024-03-07T17:10:40.864194Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Train data len:21401\nClass distributionCounter({0: 8563, 2: 6700, 1: 6138})\nValid data len:5351\nClass distributionCounter({0: 2141, 2: 1675, 1: 1535})\nTest data len:3434\nClass distributionCounter({0: 1376, 2: 1075, 1: 983})\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(232)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:40.867274Z","iopub.execute_input":"2024-03-07T17:10:40.867665Z","iopub.status.idle":"2024-03-07T17:10:40.875683Z","shell.execute_reply.started":"2024-03-07T17:10:40.867640Z","shell.execute_reply":"2024-03-07T17:10:40.874723Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7ebe908f1230>"},"metadata":{}}]},{"cell_type":"code","source":"from torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator\n\ntokenizer = get_tokenizer('basic_english')\ntrain_iter = train_dat\ndef yield_tokens(data_iter):\n    for _, text in data_iter:\n        yield tokenizer(text)\n\nvocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\nvocab.set_default_index(vocab[\"<unk>\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:40.878424Z","iopub.execute_input":"2024-03-07T17:10:40.879595Z","iopub.status.idle":"2024-03-07T17:10:41.280913Z","shell.execute_reply.started":"2024-03-07T17:10:40.879563Z","shell.execute_reply":"2024-03-07T17:10:41.279790Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"text_pipeline = lambda x: vocab(tokenizer(x))\nlabel_pipeline = lambda x: int(x) ","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.282925Z","iopub.execute_input":"2024-03-07T17:10:41.283627Z","iopub.status.idle":"2024-03-07T17:10:41.289964Z","shell.execute_reply.started":"2024-03-07T17:10:41.283577Z","shell.execute_reply":"2024-03-07T17:10:41.288418Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"text_pipeline('here is the an example')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.291716Z","iopub.execute_input":"2024-03-07T17:10:41.292377Z","iopub.status.idle":"2024-03-07T17:10:41.302143Z","shell.execute_reply.started":"2024-03-07T17:10:41.292336Z","shell.execute_reply":"2024-03-07T17:10:41.300761Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"[62, 0, 1, 0, 12881]"},"metadata":{}}]},{"cell_type":"code","source":"label_pipeline('1')","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.303965Z","iopub.execute_input":"2024-03-07T17:10:41.304584Z","iopub.status.idle":"2024-03-07T17:10:41.314066Z","shell.execute_reply.started":"2024-03-07T17:10:41.304540Z","shell.execute_reply":"2024-03-07T17:10:41.312812Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"\n\ndef collate_batch(batch):\n    label_list, text_list, offsets = [], [], [0]\n    for (_label, _text) in batch:\n        label_list.append(label_pipeline(_label))\n        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n        text_list.append(processed_text)\n        offsets.append(processed_text.size(0))\n    label_list = torch.tensor(label_list, dtype=torch.int64)\n    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n    text_list = torch.cat(text_list)\n    return label_list.to(device), text_list.to(device), offsets.to(device)\n\n#train_iter =train_dat\n#dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.315483Z","iopub.execute_input":"2024-03-07T17:10:41.316132Z","iopub.status.idle":"2024-03-07T17:10:41.323618Z","shell.execute_reply.started":"2024-03-07T17:10:41.316093Z","shell.execute_reply":"2024-03-07T17:10:41.322628Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\nclass TextClassificationModel(nn.Module):\n\n    def __init__(self, vocab_size, embed_dim, num_class):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n        self.fc1 = nn.Linear(embed_dim,64)\n        self.fc2 = nn.Linear(64,16)\n        self.fc3 = nn.Linear(16, num_class)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.5\n        self.embedding.weight.data.uniform_(-initrange, initrange)\n        self.fc1.weight.data.uniform_(-initrange, initrange)\n        self.fc1.bias.data.zero_()\n        self.fc2.weight.data.uniform_(-initrange, initrange)\n        self.fc2.bias.data.zero_()\n        self.fc3.weight.data.uniform_(-initrange, initrange)\n        self.fc3.bias.data.zero_()\n\n    def forward(self, text, offsets):\n        embedded = self.embedding(text, offsets)\n        x = F.relu(self.fc1(embedded))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.324923Z","iopub.execute_input":"2024-03-07T17:10:41.325301Z","iopub.status.idle":"2024-03-07T17:10:41.338460Z","shell.execute_reply.started":"2024-03-07T17:10:41.325222Z","shell.execute_reply":"2024-03-07T17:10:41.337464Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"train_iter1 = train_dat\nnum_class = len(set([label for (label, text) in train_iter1]))\nprint(num_class)\nvocab_size = len(vocab)\nemsize = 128\nmodel = TextClassificationModel(vocab_size, emsize, num_class).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.342000Z","iopub.execute_input":"2024-03-07T17:10:41.342441Z","iopub.status.idle":"2024-03-07T17:10:41.414473Z","shell.execute_reply.started":"2024-03-07T17:10:41.342403Z","shell.execute_reply":"2024-03-07T17:10:41.412703Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\n\ndef train(dataloader, model):\n    model.train()\n    total_acc, total_count = 0, 0\n    log_interval = 500\n    start_time = time.time()\n\n    for idx, (label, text, offsets) in enumerate(dataloader):\n        optimizer.zero_grad()\n        predited_label = model(text, offsets)\n        loss = criterion(predited_label, label)\n        loss.backward()\n        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optimizer.step()\n        total_acc += (predited_label.argmax(1) == label).sum().item()\n        total_count += label.size(0)\n        if idx % log_interval == 0 and idx > 0:\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches '\n                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n                                              total_acc/total_count))\n            total_acc, total_count = 0, 0\n            start_time = time.time()\n\ndef evaluate(dataloader):\n    model.eval()\n    total_acc, total_count = 0, 0\n\n    with torch.no_grad():\n        for idx, (label, text, offsets) in enumerate(dataloader):\n            predited_label = model(text, offsets)\n            loss = criterion(predited_label, label)\n            total_acc += (predited_label.argmax(1) == label).sum().item()\n            total_count += label.size(0)\n    return total_acc/total_count","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.415896Z","iopub.execute_input":"2024-03-07T17:10:41.416306Z","iopub.status.idle":"2024-03-07T17:10:41.427978Z","shell.execute_reply.started":"2024-03-07T17:10:41.416274Z","shell.execute_reply":"2024-03-07T17:10:41.426420Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def convert_to_dense(model):\n    for name, param in model.parameters():\n        if param.is_sparse:\n            new_param = param.to_dense()\n            setattr(model, name, new_param)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.429874Z","iopub.execute_input":"2024-03-07T17:10:41.430522Z","iopub.status.idle":"2024-03-07T17:10:41.441312Z","shell.execute_reply.started":"2024-03-07T17:10:41.430479Z","shell.execute_reply":"2024-03-07T17:10:41.439639Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def custom_clip_sparse_gradients(grads, max_norm):\n    values, indices, shape = grads.coalesce()\n    clipped_values = torch.clamp(values, -max_norm, max_norm)\n    return torch.sparse.Sparse(indices, clipped_values, shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.443748Z","iopub.execute_input":"2024-03-07T17:10:41.444367Z","iopub.status.idle":"2024-03-07T17:10:41.452661Z","shell.execute_reply.started":"2024-03-07T17:10:41.444324Z","shell.execute_reply":"2024-03-07T17:10:41.451820Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import random_split\nfrom torchtext.data.functional import to_map_style_dataset\n# Hyperparameters\nEPOCHS = 20 # epoch\nLR =0.1  # learning rate\nBATCH_SIZE = 8 # batch size for training\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\ntotal_accu = None\n\ntrain_iter2 = train_dat\ntest_iter2 =test_dat \nvalid_iter2= valid_dat\n\n\n\n\ntrain_dataloader = DataLoader(train_iter2, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\nvalid_dataloader = DataLoader(valid_iter2, batch_size=BATCH_SIZE,\n                              shuffle=True, collate_fn=collate_batch)\ntest_dataloader = DataLoader(test_iter2, batch_size=BATCH_SIZE,\n                             shuffle=True, collate_fn=collate_batch)\n\n\n\nfor epoch in range(1, EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_dataloader, model)\n    accu_val = evaluate(valid_dataloader)\n    if total_accu is not None and total_accu > accu_val:\n        scheduler.step()\n    else:\n        total_accu = accu_val\n    print('-' * 59)\n    print('| end of epoch {:3d} | time: {:5.2f}s | '\n          'valid accuracy {:8.3f} '.format(epoch,\n                                           time.time() - epoch_start_time,\n                                           accu_val))\n    print('-' * 59)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:10:41.453508Z","iopub.execute_input":"2024-03-07T17:10:41.453804Z","iopub.status.idle":"2024-03-07T17:12:00.040539Z","shell.execute_reply.started":"2024-03-07T17:10:41.453781Z","shell.execute_reply":"2024-03-07T17:12:00.039341Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"| epoch   1 |   500/ 2676 batches | accuracy    0.419\n| epoch   1 |  1000/ 2676 batches | accuracy    0.488\n| epoch   1 |  1500/ 2676 batches | accuracy    0.502\n| epoch   1 |  2000/ 2676 batches | accuracy    0.529\n| epoch   1 |  2500/ 2676 batches | accuracy    0.546\n-----------------------------------------------------------\n| end of epoch   1 | time:  3.93s | valid accuracy    0.568 \n-----------------------------------------------------------\n| epoch   2 |   500/ 2676 batches | accuracy    0.617\n| epoch   2 |  1000/ 2676 batches | accuracy    0.593\n| epoch   2 |  1500/ 2676 batches | accuracy    0.612\n| epoch   2 |  2000/ 2676 batches | accuracy    0.621\n| epoch   2 |  2500/ 2676 batches | accuracy    0.616\n-----------------------------------------------------------\n| end of epoch   2 | time:  3.92s | valid accuracy    0.573 \n-----------------------------------------------------------\n| epoch   3 |   500/ 2676 batches | accuracy    0.650\n| epoch   3 |  1000/ 2676 batches | accuracy    0.651\n| epoch   3 |  1500/ 2676 batches | accuracy    0.655\n| epoch   3 |  2000/ 2676 batches | accuracy    0.657\n| epoch   3 |  2500/ 2676 batches | accuracy    0.655\n-----------------------------------------------------------\n| end of epoch   3 | time:  3.87s | valid accuracy    0.632 \n-----------------------------------------------------------\n| epoch   4 |   500/ 2676 batches | accuracy    0.692\n| epoch   4 |  1000/ 2676 batches | accuracy    0.698\n| epoch   4 |  1500/ 2676 batches | accuracy    0.691\n| epoch   4 |  2000/ 2676 batches | accuracy    0.700\n| epoch   4 |  2500/ 2676 batches | accuracy    0.702\n-----------------------------------------------------------\n| end of epoch   4 | time:  3.91s | valid accuracy    0.624 \n-----------------------------------------------------------\n| epoch   5 |   500/ 2676 batches | accuracy    0.736\n| epoch   5 |  1000/ 2676 batches | accuracy    0.745\n| epoch   5 |  1500/ 2676 batches | accuracy    0.745\n| epoch   5 |  2000/ 2676 batches | accuracy    0.741\n| epoch   5 |  2500/ 2676 batches | accuracy    0.741\n-----------------------------------------------------------\n| end of epoch   5 | time:  3.92s | valid accuracy    0.640 \n-----------------------------------------------------------\n| epoch   6 |   500/ 2676 batches | accuracy    0.751\n| epoch   6 |  1000/ 2676 batches | accuracy    0.747\n| epoch   6 |  1500/ 2676 batches | accuracy    0.751\n| epoch   6 |  2000/ 2676 batches | accuracy    0.747\n| epoch   6 |  2500/ 2676 batches | accuracy    0.750\n-----------------------------------------------------------\n| end of epoch   6 | time:  3.95s | valid accuracy    0.643 \n-----------------------------------------------------------\n| epoch   7 |   500/ 2676 batches | accuracy    0.755\n| epoch   7 |  1000/ 2676 batches | accuracy    0.763\n| epoch   7 |  1500/ 2676 batches | accuracy    0.753\n| epoch   7 |  2000/ 2676 batches | accuracy    0.750\n| epoch   7 |  2500/ 2676 batches | accuracy    0.755\n-----------------------------------------------------------\n| end of epoch   7 | time:  4.13s | valid accuracy    0.642 \n-----------------------------------------------------------\n| epoch   8 |   500/ 2676 batches | accuracy    0.766\n| epoch   8 |  1000/ 2676 batches | accuracy    0.758\n| epoch   8 |  1500/ 2676 batches | accuracy    0.757\n| epoch   8 |  2000/ 2676 batches | accuracy    0.772\n| epoch   8 |  2500/ 2676 batches | accuracy    0.760\n-----------------------------------------------------------\n| end of epoch   8 | time:  3.92s | valid accuracy    0.638 \n-----------------------------------------------------------\n| epoch   9 |   500/ 2676 batches | accuracy    0.762\n| epoch   9 |  1000/ 2676 batches | accuracy    0.765\n| epoch   9 |  1500/ 2676 batches | accuracy    0.764\n| epoch   9 |  2000/ 2676 batches | accuracy    0.769\n| epoch   9 |  2500/ 2676 batches | accuracy    0.765\n-----------------------------------------------------------\n| end of epoch   9 | time:  3.95s | valid accuracy    0.638 \n-----------------------------------------------------------\n| epoch  10 |   500/ 2676 batches | accuracy    0.765\n| epoch  10 |  1000/ 2676 batches | accuracy    0.761\n| epoch  10 |  1500/ 2676 batches | accuracy    0.759\n| epoch  10 |  2000/ 2676 batches | accuracy    0.766\n| epoch  10 |  2500/ 2676 batches | accuracy    0.770\n-----------------------------------------------------------\n| end of epoch  10 | time:  3.89s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  11 |   500/ 2676 batches | accuracy    0.773\n| epoch  11 |  1000/ 2676 batches | accuracy    0.773\n| epoch  11 |  1500/ 2676 batches | accuracy    0.751\n| epoch  11 |  2000/ 2676 batches | accuracy    0.767\n| epoch  11 |  2500/ 2676 batches | accuracy    0.762\n-----------------------------------------------------------\n| end of epoch  11 | time:  3.91s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  12 |   500/ 2676 batches | accuracy    0.754\n| epoch  12 |  1000/ 2676 batches | accuracy    0.758\n| epoch  12 |  1500/ 2676 batches | accuracy    0.766\n| epoch  12 |  2000/ 2676 batches | accuracy    0.764\n| epoch  12 |  2500/ 2676 batches | accuracy    0.778\n-----------------------------------------------------------\n| end of epoch  12 | time:  3.94s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  13 |   500/ 2676 batches | accuracy    0.770\n| epoch  13 |  1000/ 2676 batches | accuracy    0.767\n| epoch  13 |  1500/ 2676 batches | accuracy    0.762\n| epoch  13 |  2000/ 2676 batches | accuracy    0.765\n| epoch  13 |  2500/ 2676 batches | accuracy    0.766\n-----------------------------------------------------------\n| end of epoch  13 | time:  3.88s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  14 |   500/ 2676 batches | accuracy    0.761\n| epoch  14 |  1000/ 2676 batches | accuracy    0.769\n| epoch  14 |  1500/ 2676 batches | accuracy    0.762\n| epoch  14 |  2000/ 2676 batches | accuracy    0.771\n| epoch  14 |  2500/ 2676 batches | accuracy    0.763\n-----------------------------------------------------------\n| end of epoch  14 | time:  3.87s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  15 |   500/ 2676 batches | accuracy    0.754\n| epoch  15 |  1000/ 2676 batches | accuracy    0.756\n| epoch  15 |  1500/ 2676 batches | accuracy    0.782\n| epoch  15 |  2000/ 2676 batches | accuracy    0.768\n| epoch  15 |  2500/ 2676 batches | accuracy    0.757\n-----------------------------------------------------------\n| end of epoch  15 | time:  4.11s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  16 |   500/ 2676 batches | accuracy    0.765\n| epoch  16 |  1000/ 2676 batches | accuracy    0.764\n| epoch  16 |  1500/ 2676 batches | accuracy    0.765\n| epoch  16 |  2000/ 2676 batches | accuracy    0.750\n| epoch  16 |  2500/ 2676 batches | accuracy    0.766\n-----------------------------------------------------------\n| end of epoch  16 | time:  3.89s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  17 |   500/ 2676 batches | accuracy    0.761\n| epoch  17 |  1000/ 2676 batches | accuracy    0.763\n| epoch  17 |  1500/ 2676 batches | accuracy    0.764\n| epoch  17 |  2000/ 2676 batches | accuracy    0.765\n| epoch  17 |  2500/ 2676 batches | accuracy    0.766\n-----------------------------------------------------------\n| end of epoch  17 | time:  3.84s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  18 |   500/ 2676 batches | accuracy    0.755\n| epoch  18 |  1000/ 2676 batches | accuracy    0.755\n| epoch  18 |  1500/ 2676 batches | accuracy    0.774\n| epoch  18 |  2000/ 2676 batches | accuracy    0.761\n| epoch  18 |  2500/ 2676 batches | accuracy    0.772\n-----------------------------------------------------------\n| end of epoch  18 | time:  3.93s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  19 |   500/ 2676 batches | accuracy    0.762\n| epoch  19 |  1000/ 2676 batches | accuracy    0.762\n| epoch  19 |  1500/ 2676 batches | accuracy    0.764\n| epoch  19 |  2000/ 2676 batches | accuracy    0.775\n| epoch  19 |  2500/ 2676 batches | accuracy    0.763\n-----------------------------------------------------------\n| end of epoch  19 | time:  3.89s | valid accuracy    0.637 \n-----------------------------------------------------------\n| epoch  20 |   500/ 2676 batches | accuracy    0.765\n| epoch  20 |  1000/ 2676 batches | accuracy    0.770\n| epoch  20 |  1500/ 2676 batches | accuracy    0.755\n| epoch  20 |  2000/ 2676 batches | accuracy    0.767\n| epoch  20 |  2500/ 2676 batches | accuracy    0.766\n-----------------------------------------------------------\n| end of epoch  20 | time:  3.92s | valid accuracy    0.637 \n-----------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Checking the results of test dataset.')\naccu_test = evaluate(test_dataloader)\nprint('test accuracy {:8.3f}'.format(accu_test))","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:12:00.041984Z","iopub.execute_input":"2024-03-07T17:12:00.042349Z","iopub.status.idle":"2024-03-07T17:12:00.284398Z","shell.execute_reply.started":"2024-03-07T17:12:00.042321Z","shell.execute_reply":"2024-03-07T17:12:00.283341Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Checking the results of test dataset.\ntest accuracy    0.636\n","output_type":"stream"}]},{"cell_type":"code","source":"sentiment_label = {2:\"Positive\",\n                   1: \"Negative\",\n                   0: \"Neutral\"\n                  }\n\ndef predict(text, text_pipeline):\n    with torch.no_grad():\n        text = torch.tensor(text_pipeline(text))\n        output = model(text, torch.tensor([0]))\n        return output.argmax(1).item() \na=\"i hate him\"\nex_text_str = a\nmodel = model.to(\"cpu\")\n\nprint(\"This is a %s comment\" %sentiment_label[predict(ex_text_str, text_pipeline)])","metadata":{"execution":{"iopub.status.busy":"2024-03-07T17:14:20.428381Z","iopub.execute_input":"2024-03-07T17:14:20.428813Z","iopub.status.idle":"2024-03-07T17:14:20.437872Z","shell.execute_reply.started":"2024-03-07T17:14:20.428785Z","shell.execute_reply":"2024-03-07T17:14:20.436392Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"This is a Negative comment\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}